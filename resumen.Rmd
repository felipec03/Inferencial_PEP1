---
title: "Resumen PEP 1 - Estadística Inferencial"
author: "Felipe Cubillos"
date: "2025-05-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(TeachingDemos)
library(ggplot2)
library(ggpubr)
```

# Inferencia con medias muestrales

## Prueba Z

> La prueba Z es adecuada para inferir acerca de las medias con una o dos muestras. Esta prueba resulta adecuada si queremos asegurar o descartar que la media de la población tiene un cierto valor hipotético.

- Las observaciones deben ser independientes, es decir que la elección de una observación para la muestrano influye en la selección de las otras.
- La población de donde se obtuvo la muestra sigue aproximadamente una distribución normal. **Gráfico Q-Q o Shapiro-Wilk**.
- La muestra debe tener al menos 30 observaciones (y asumir que la varianza observada corresponde a la varianza de la población). 
- Si la muestra tiene menos de 30 observaciones, se debe conocer la **varianza** de la población

$$
H_0 := \mu_{poblacional} = \mu_{nulo} \\
H_A := \mu_{poblacional} \neq \mu_{nulo}
$$

Si generamos una muestra de tamaño 50, de media real 5 y desviación estandar 1, queremos inferir sobre la población y queremos saber si el valor hipotético de este es 5.

```{r}
set.seed(128)
muestra <- rnorm(50, mean = 5, sd = 1)
alpha <- 0.05
valor_nulo <- 5
```

Para verificar normalidad, se utiliza el test de Shapiro-Wilk, cuyas hipótesis son:

- $H_0$: El "arreglo" de valores (muestra) sigue una distribución normal.
- $H_A$: El "arreglo" de valores (muestra) NO sigue una distribución normal.

```{r}
# normalidad
ggqqplot(data = data.frame(muestra), x = "muestra", color = "steelblue")
shapiro.test(muestra)

# prueba
z.test(muestra, mu = valor_nulo, alternative = "two.sided", stdev = 1, conf.level = 1-alpha)
```

De la prueba, se obtiene un p-value mayor que $\alpha$, por tanto **los datos sugieren que no podemos rechazar la hipótesis nula.**

## Prueba T de Student (t-test)
> Las condiciones son casi las mismas que para la prueba Z, excepto por el hecho de que noexige que el tamaño de la muestra sea mayor a 30. La ventaja evidente de eliminar esta restricción es que la distribución t permite su uso para muestras pequeñas, pero es igualmente adecuada cuando la muestra es grande.

- Observaciones independientes entre sí.
- Observaciones provienen de una distribución cercana a la normal.

```{r}
t.test(muestra, mu = valor_nulo, alternative = "two.sided", conf.level = 1-alpha)
```

### t-test para muestras pareadas
> *"Dos muestras son pareadas cuando las observaciones en una muestra están relacionadas o conectadas de alguna forma con las observaciones en la otra muestra. Las observaciones están relacionadas por un criterio de selección o comparación o están relacionadas por el mismo sujeto o unidad experimental"*

**Ejemplo:** Se quieren comparar dos algoritmos de ordenamiento y su tiempo promedio de ejecución, cómo de el mismo arreglo aparecen 2 tiempos de ejecución asociados a A y B, entonces estos tiempos son apareados.

> Inferimos sobre media de las diferencias ($\mu_{diff}$), **no es lo mismo que diferencia de medias -> independiente**.

- $H_0$: Media de las diferencias es igual a 0. 
- $H_A$: Media de las diferencias distinto de 0.

```{r}
muestra2 <- rnorm(50, mean = 5.1, sd = 1)
t.test(x = muestra, y = muestra2, paired = TRUE, mu = valor_nulo, alternative = "two.sided", conf.level = 1-alpha)
```

### t-test para muestras independientes
> En este caso la **inferencia se hace sobre la diferencia de las medias:** $\mu_A − \mu_B = d0$, donde $d0$ es un valor hipotético fijo para la diferencia. Usualmente se usa $d0 = 0$, en cuyo caso las muestras podrían provenir de dos poblaciones distintas con igual media, o desde la misma población.

1. Cada muestra cumple las condiciones para usar la distribución t.
2. Las muestras son independientes entre sí.

- $H_0$: No hay diferencia entre las medias, se puede decir que la efectividad promedio es la misma para A y B, entonces $\mu_A = \mu_B$
- $H_A$: Una muestra A es distinta en promedio a una muestra B, se puede decir que es "mejor" que otra (efectividad, satisfacción, etc...), entonces $\mu_A > \mu_B$.


```{r}
muestra2 <- rnorm(50, mean = 5.1, sd = 1)
t.test(x = muestra, y = muestra2, paired = FALSE, mu = valor_nulo, alternative = "two.sided", conf.level = 1-alpha)
```

# Inferencia con proporciones muestrales

## Método de Wald
> En general, no conocemos la probabilidad de éxito $p$ de la población, por lo que tenemos que usar el estimador puntual (correspondientea la proporción de éxito de la muestra), denotado por $\hat{p}$. Este estimador se distribuye de manera cercana a la normal cuando se cumplen las siguientes condiciones:

- Observaciones de la muestra son independientes entre sí.
- Se cumple la condición de éxito-fracaso: Se espera observar **al menos** 10 observaciones correspondientes a éxitos y 10 a fracasos.

### Método de Wald para una proporción
- $H_0$: Una parte de una población (n por ciento) cumplen una condición. *Ejemplo: El 90% de los encuestados tiene más de 3 personas viviendo en su hogar.* $p = p_0$.
- $H_A$: Una parte de una población (n por ciento) NO cumplen con la condición. *Ejemplo: Menos del 90% de los encuestados tiene menos de 3 personas viviendo en su hogar.* $p < p_0$.

Notemos que, $p_0$ en este ejemplo sería $0.9$ y el estimador sería $p$.

### Método de Wald para dos proporciones
> También podemos usar el método de Wald para estudiar la diferencia entre las proporciones de dos poblaciones, considerando para ello como estimador puntual la diferencia $\hat{p1} − \hat{p2}$.

## Método de Wilson